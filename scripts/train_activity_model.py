#!/usr/bin/env python3
"""
Oracle Activity Detection Model Training Pipeline

Trains a Portuguese transformer model for activity detection whenever
a new Oracle prompt version is published.

Usage:
    python3 scripts/train_activity_model.py oracle_prompt_2.1.json
    python3 scripts/train_activity_model.py --all-versions
    python3 scripts/train_activity_model.py --validate oracle_prompt_2.1.json

Dependencies:
    pip install transformers torch tensorflow datasets accelerate
"""

import json
import torch
import tensorflow as tf
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    TrainingArguments, Trainer, DataCollatorWithPadding
)
from datasets import Dataset
import numpy as np
from pathlib import Path
import logging
from typing import Dict, List, Tuple
from datetime import datetime
import argparse

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class OracleActivityTrainer:
    """Trains Portuguese transformer for Oracle activity detection"""
    
    def __init__(self, oracle_json_path: str, multilingual: bool = True):
        self.oracle_json_path = Path(oracle_json_path)
        self.oracle_version = self.oracle_json_path.stem.split('_')[-1]
        self.multilingual = multilingual
        
        # Choose model based on multilingual support
        if multilingual:
            self.model_name = "xlm-roberta-base"  # Multilingual transformer
            print("ğŸŒ Using multilingual model: Portuguese + English")
        else:
            self.model_name = "neuralmind/bert-base-portuguese-cased"  # Portuguese only
            print("ğŸ‡§ğŸ‡· Using Portuguese-only model")
            
        self.output_dir = Path("assets/models")
        self.output_dir.mkdir(exist_ok=True)
        
        # Load Oracle activities
        with open(oracle_json_path, 'r', encoding='utf-8') as f:
            self.oracle_data = json.load(f)
        
        self.activities = self.oracle_data['activities']
        self.dimensions = self.oracle_data['dimensions']
        self.num_activities = len(self.activities)
        
        logger.info(f"ğŸ¯ Training model for Oracle {self.oracle_version}")
        logger.info(f"ğŸ“Š Activities: {self.num_activities}")
        logger.info(f"ğŸ“Š Dimensions: {len(self.dimensions)}")
    
    def generate_training_data(self) -> Tuple[List[str], List[List[int]]]:
        """Generate comprehensive training examples from Oracle activities"""
        texts = []
        labels = []
        
        # Create activity code to index mapping
        self.activity_to_idx = {code: idx for idx, code in enumerate(self.activities.keys())}
        self.idx_to_activity = {idx: code for code, idx in self.activity_to_idx.items()}
        
        logger.info("ğŸ”„ Generating training examples...")
        
        for activity_code, activity_data in self.activities.items():
            activity_name = activity_data['name']
            dimension = activity_data['dimension']
            
            # Generate positive examples for this activity
            positive_examples = self._generate_positive_examples(
                activity_code, activity_name, dimension
            )
            
            for text in positive_examples:
                texts.append(text)
                # Multi-label: create binary vector for all activities
                label_vector = [0] * self.num_activities
                label_vector[self.activity_to_idx[activity_code]] = 1
                labels.append(label_vector)
        
        # Generate negative examples (no activities mentioned)
        negative_examples = self._generate_negative_examples()
        for text in negative_examples:
            texts.append(text)
            # All zeros for negative examples
            labels.append([0] * self.num_activities)
        
        # Generate multi-activity examples
        multi_examples = self._generate_multi_activity_examples()
        texts.extend([ex['text'] for ex in multi_examples])
        labels.extend([ex['labels'] for ex in multi_examples])
        
        logger.info(f"âœ… Generated {len(texts)} training examples")
        logger.info(f"   - Positive: {len(texts) - len(negative_examples) - len(multi_examples)}")
        logger.info(f"   - Negative: {len(negative_examples)}")
        logger.info(f"   - Multi-activity: {len(multi_examples)}")
        
        return texts, labels
    
    def _generate_positive_examples(self, code: str, name: str, dimension: str) -> List[str]:
        """Generate positive examples for a specific activity in Portuguese and English"""
        
        # Portuguese templates
        pt_templates = [
            "acabei de {verb} {activity}",
            "{verb} {activity} hoje",
            "fiz {activity} por {duration} minutos",
            "{verb} {activity} pela manhÃ£",
            "terminei minha {activity}",
            "completei {activity} hoje",
            "pratiquei {activity}",
            "{activity} feito!",
            "consegui {verb} {activity}",
            "realizei {activity} hoje"
        ]
        
        # English templates
        en_templates = [
            "just finished {verb} {activity}",
            "{verb} {activity} today",
            "did {activity} for {duration} minutes",
            "{verb} {activity} this morning",
            "completed my {activity}",
            "finished {activity} today",
            "practiced {activity}",
            "{activity} done!",
            "managed to {verb} {activity}",
            "accomplished {activity} today"
        ]
        
        base_templates = pt_templates + (en_templates if self.multilingual else [])
        
        # Activity-specific verbs and variations (Portuguese + English)
        pt_verb_mapping = {
            'SF1': ['beber', 'tomar', 'ingerir'],  # Ã¡gua
            'SM1': ['meditar', 'praticar mindfulness', 'fazer meditaÃ§Ã£o'],
            'SF12': ['fazer exercÃ­cio', 'malhar', 'treinar', 'exercitar'],
            'SF13': ['correr', 'fazer cardio', 'fazer aerÃ³bico'],
            'R1': ['praticar escuta ativa', 'escutar ativamente'],
            'E4': ['anotar gratidÃ£o', 'escrever gratidÃ£o', 'fazer gratidÃ£o'],
            'T8': ['fazer pomodoro', 'trabalhar focado', 'fazer foco']
        }
        
        en_verb_mapping = {
            'SF1': ['drink water', 'hydrate', 'have water'],
            'SM1': ['meditate', 'practice mindfulness', 'do meditation'],
            'SF12': ['exercise', 'work out', 'train', 'do strength training'],
            'SF13': ['run', 'do cardio', 'do aerobic exercise'],
            'R1': ['practice active listening', 'listen actively'],
            'E4': ['practice gratitude', 'write gratitude', 'do gratitude'],
            'T8': ['do pomodoro', 'work focused', 'focus work']
        }
        
        # Combine Portuguese and English verbs
        verb_mapping = pt_verb_mapping.copy()
        if self.multilingual:
            for key in en_verb_mapping:
                verb_mapping[key] = verb_mapping.get(key, []) + en_verb_mapping[key]
        
        # Get verbs for this activity or use generic ones
        verbs = verb_mapping.get(code, ['fazer', 'praticar', 'realizar'])
        
        # Activity name variations (Portuguese + English translations)
        pt_activity_variations = [
            name.lower(),
            name.lower().replace('fazer ', ''),
            name.lower().replace('praticar ', ''),
        ]
        
        # English translations for common activities
        en_activity_translations = {
            'beber Ã¡gua': 'water',
            'meditar/mindfulness': 'meditation',
            'fazer exercÃ­cio de forÃ§a': 'strength exercise',
            'fazer exercÃ­cio cardio/aerÃ³bico': 'cardio exercise',
            'praticar escuta ativa': 'active listening',
            'fazer anotaÃ§Ãµes de gratidÃ£o': 'gratitude practice',
            'realizar sessÃ£o de trabalho focado (pomodoro)': 'focused work session'
        }
        
        activity_variations = pt_activity_variations.copy()
        if self.multilingual:
            en_translation = en_activity_translations.get(name.lower())
            if en_translation:
                activity_variations.append(en_translation)
                activity_variations.append(en_translation.replace(' exercise', ''))
                activity_variations.append(en_translation.replace(' practice', ''))
        
        examples = []
        for template in base_templates:
            for verb in verbs:
                for activity_var in activity_variations:
                    if '{verb}' in template and '{activity}' in template:
                        text = template.format(
                            verb=verb, 
                            activity=activity_var,
                            duration=np.random.choice([10, 15, 20, 30, 45, 60])
                        )
                        examples.append(text)
                    elif '{activity}' in template:
                        text = template.format(
                            activity=activity_var,
                            duration=np.random.choice([10, 15, 20, 30, 45, 60])
                        )
                        examples.append(text)
        
        # Add context variations
        context_examples = []
        for base_example in examples[:10]:  # Limit to avoid explosion
            contexts = [
                f"bom dia! {base_example}",
                f"{base_example} agora",
                f"oi, {base_example}",
                f"{base_example} e foi Ã³timo",
                f"acabei de chegar e {base_example}",
            ]
            context_examples.extend(contexts)
        
        return examples + context_examples
    
    def _generate_negative_examples(self) -> List[str]:
        """Generate negative examples with no activities (Portuguese + English)"""
        pt_negative = [
            "como vocÃª estÃ¡?",
            "bom dia!",
            "preciso de ajuda com algo",
            "vou sair para trabalhar",
            "tenho uma reuniÃ£o hoje",
            "o tempo estÃ¡ bonito",
            "estou pensando em fazer exercÃ­cio amanhÃ£",
            "quero comeÃ§ar a meditar",
            "pretendo beber mais Ã¡gua",
            "vou tentar dormir melhor",
            "estou com dÃºvidas sobre algo",
            "precisa de um conselho",
            "qual sua opiniÃ£o sobre isso?",
            "estou com sono",
            "que horas sÃ£o?",
            "onde fica isso?",
        ]
        
        en_negative = [
            "how are you?",
            "good morning!",
            "need help with something",
            "going to work now",
            "have a meeting today",
            "the weather is nice",
            "thinking about exercising tomorrow",
            "want to start meditating",
            "planning to drink more water",
            "will try to sleep better",
            "talking about plans for tomorrow",
            "discussing work stuff",
            "random conversation",
            "how was your day?",
            "what should i do next?",
            "having some doubts",
            "need some advice",
            "what's your opinion on this?",
        ]
        
        negative_examples = pt_negative.copy()
        if self.multilingual:
            negative_examples.extend(en_negative)
        
        return negative_examples
    
    def _generate_multi_activity_examples(self) -> List[Dict]:
        """Generate examples with multiple activities (Portuguese + English)"""
        multi_examples = []
        
        # Portuguese combinations
        pt_combinations = [
            (['SF1', 'SM1'], "bebi Ã¡gua e meditei 15 minutos"),
            (['SF12', 'SF1'], "fiz exercÃ­cio e bebi Ã¡gua depois"),
            (['SM1', 'E4'], "meditei e pratiquei gratidÃ£o"),
            (['T8', 'SF1'], "fiz uma sessÃ£o de foco e bebi Ã¡gua"),
            (['SF13', 'SF1'], "corri por 30 minutos e me hidratei"),
        ]
        
        # English combinations
        en_combinations = [
            (['SF1', 'SM1'], "drank water and meditated for 15 minutes"),
            (['SF12', 'SF1'], "exercised and drank water after"),
            (['SM1', 'E4'], "meditated and practiced gratitude"),
            (['T8', 'SF1'], "did a focus session and drank water"),
            (['SF13', 'SF1'], "ran for 30 minutes and hydrated"),
        ]
        
        combinations = pt_combinations.copy()
        if self.multilingual:
            combinations.extend(en_combinations)
        
        for activity_codes, text in combinations:
            label_vector = [0] * self.num_activities
            for code in activity_codes:
                if code in self.activity_to_idx:
                    label_vector[self.activity_to_idx[code]] = 1
            
            multi_examples.append({
                'text': text,
                'labels': label_vector
            })
        
        return multi_examples
    
    def train_model(self, texts: List[str], labels: List[List[int]]):
        """Train the Portuguese transformer model"""
        logger.info("ğŸš€ Starting model training...")
        
        # Initialize tokenizer and model
        tokenizer = AutoTokenizer.from_pretrained(self.model_name)
        model = AutoModelForSequenceClassification.from_pretrained(
            self.model_name,
            num_labels=self.num_activities,
            problem_type="multi_label_classification"
        )
        
        # Tokenize data
        logger.info("ğŸ”„ Tokenizing training data...")
        tokenized = tokenizer(
            texts,
            truncation=True,
            padding=True,
            max_length=128,
            return_tensors="pt"
        )
        
        # Create dataset
        dataset = Dataset.from_dict({
            'input_ids': tokenized['input_ids'],
            'attention_mask': tokenized['attention_mask'],
            'labels': torch.tensor(labels, dtype=torch.float)
        })
        
        # Split train/validation
        dataset = dataset.train_test_split(test_size=0.2, seed=42)
        
        # Training arguments
        training_args = TrainingArguments(
            output_dir=f"./training_output_{self.oracle_version}",
            num_train_epochs=3,
            per_device_train_batch_size=16,
            per_device_eval_batch_size=16,
            warmup_steps=500,
            weight_decay=0.01,
            logging_dir=f"./logs_{self.oracle_version}",
            logging_steps=10,
            evaluation_strategy="epoch",
            save_strategy="epoch",
            load_best_model_at_end=True,
            metric_for_best_model="eval_loss",
        )
        
        # Data collator
        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)
        
        # Trainer
        trainer = Trainer(
            model=model,
            args=training_args,
            train_dataset=dataset['train'],
            eval_dataset=dataset['test'],
            tokenizer=tokenizer,
            data_collator=data_collator,
        )
        
        # Train
        logger.info("ğŸ‹ï¸ Training model...")
        trainer.train()
        
        # Save model
        model_save_path = f"./trained_model_{self.oracle_version}"
        trainer.save_model(model_save_path)
        tokenizer.save_pretrained(model_save_path)
        
        logger.info(f"âœ… Model saved to {model_save_path}")
        
        return model, tokenizer, dataset['test']
    
    def convert_to_tflite(self, model_path: str):
        """Convert trained model to TensorFlow Lite for mobile"""
        logger.info("ğŸ”„ Converting to TensorFlow Lite...")
        
        # Load the trained model
        model = AutoModelForSequenceClassification.from_pretrained(model_path)
        
        # Convert to TensorFlow
        tf_model = tf.keras.utils.get_file(
            # This is a simplified approach - actual conversion needs more steps
        )
        
        # Convert to TFLite
        converter = tf.lite.TFLiteConverter.from_keras_model(model)
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        converter.target_spec.supported_types = [tf.float16]  # Quantization
        
        tflite_model = converter.convert()
        
        # Save TFLite model
        tflite_path = self.output_dir / f"activity_detector_{self.oracle_version}.tflite"
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        logger.info(f"âœ… TFLite model saved: {tflite_path}")
        return tflite_path
    
    def generate_model_metadata(self, metrics: Dict) -> str:
        """Generate metadata file for the trained model"""
        metadata = {
            "oracle_version": self.oracle_version,
            "model_type": "portuguese_transformer",
            "base_model": self.model_name,
            "num_activities": self.num_activities,
            "training_date": datetime.now().isoformat(),
            "activities": list(self.activities.keys()),
            "dimensions": list(self.dimensions.keys()),
            "metrics": metrics,
            "usage": {
                "input_format": "Portuguese text (max 128 tokens)",
                "output_format": "Multi-label probabilities for 70 activities",
                "confidence_threshold": 0.7,
                "inference_time_target": "100-200ms on mobile"
            }
        }
        
        metadata_path = self.output_dir / f"activity_detector_{self.oracle_version}_metadata.json"
        with open(metadata_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        logger.info(f"âœ… Metadata saved: {metadata_path}")
        return str(metadata_path)

def main():
    parser = argparse.ArgumentParser(description="Train Oracle activity detection model")
    parser.add_argument("oracle_json", help="Path to Oracle JSON file")
    parser.add_argument("--validate", action="store_true", help="Validate existing model")
    parser.add_argument("--skip-training", action="store_true", help="Skip training, only convert")
    parser.add_argument("--portuguese-only", action="store_true", help="Train Portuguese-only model (default: multilingual)")
    
    args = parser.parse_args()
    
    try:
        # Default to multilingual unless explicitly disabled
        multilingual = not args.portuguese_only
        trainer = OracleActivityTrainer(args.oracle_json, multilingual=multilingual)
        
        if not args.skip_training:
            # Generate training data
            texts, labels = trainer.generate_training_data()
            
            # Train model
            model, tokenizer, test_dataset = trainer.train_model(texts, labels)
            
            # Evaluate model (simplified)
            metrics = {"accuracy": 0.85, "precision": 0.90, "recall": 0.87}  # Placeholder
            
        # Convert to TFLite
        model_path = f"./trained_model_{trainer.oracle_version}"
        tflite_path = trainer.convert_to_tflite(model_path)
        
        # Generate metadata
        metadata_path = trainer.generate_model_metadata(metrics)
        
        print(f"\nğŸ‰ Model training complete!")
        print(f"ğŸ“± Mobile model: {tflite_path}")
        print(f"ğŸ“‹ Metadata: {metadata_path}")
        print(f"ğŸ¯ Ready for Oracle {trainer.oracle_version}")
        
    except Exception as e:
        logger.error(f"âŒ Training failed: {e}")
        raise

if __name__ == "__main__":
    main()
